{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load image data and text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/yxiao977/.conda/envs/pytorch/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from transformers import AutoImageProcessor, ViTModel\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from transformers import BertModel, BertTokenizer\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(13)\n",
    "\n",
    "class_ind = {'CC':0, 'EC':1, 'LGSC':2, 'HGSC':3, 'MC':4}\n",
    "\n",
    "class OvarianDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, text_dir):\n",
    "        self.img_metadata = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.texts = {}\n",
    "        for c in ['CC', 'EC', 'LGSC', 'HGSC', 'MC']:\n",
    "            self.texts[c] = pd.read_table(text_dir+c+'.txt', header=None, sep='.').iloc[:,1].to_list()\n",
    "       \n",
    "    def __len__(self):\n",
    "        return len(self.img_metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample_idx = idx\n",
    "        sample = self.img_metadata.iloc[sample_idx, 0]\n",
    "        group = self.img_metadata.iloc[sample_idx, 1]\n",
    "\n",
    "        label = torch.tensor(class_ind[group]).to(device)  \n",
    "\n",
    "        image_patches = []\n",
    "        for i in range(100):\n",
    "            img_path = self.img_dir + f'sample_{sample}' + f'/{sample}_{i}.png'\n",
    "            patch = torch.tensor(np.asarray(Image.open(img_path))[13:237, 13:237].T, dtype=torch.float32)\n",
    "            image_patches.append(patch)\n",
    "        image_patches = torch.stack(image_patches, dim=0).to(device)\n",
    "\n",
    "        text = self.texts[group][idx % 100]\n",
    "        # text = torch.tensor(self.tokenizer.encode(text, max_length=seq_max_length, padding=\"max_length\")).to(device)\n",
    "\n",
    "        return image_patches, text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset\n",
    "metadata = \"/scratch1/yuqiuwan/CSCI567/train.csv\"\n",
    "image_dir = \"/scratch1/yuqiuwan/CSCI567/preprocess_images_threshold/\"\n",
    "text_dir = \"/scratch1/yuqiuwan/CSCI567/textLabel/\"\n",
    "\n",
    "wholedataset = OvarianDataset(metadata, image_dir, text_dir)\n",
    "train_set, test_set = torch.utils.data.random_split(wholedataset, [0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build CLIP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLIP(nn.Module):\n",
    "    def __init__(self, ImageEncoder, TextEncoder, d_embed=768, n_classes=5):\n",
    "        super().__init__()\n",
    "        self.image_encoder = ImageEncoder\n",
    "        self.text_encoder = TextEncoder\n",
    "        self.image_proj = nn.Linear(d_embed, n_classes)\n",
    "        self.text_proj = nn.Linear(d_embed, n_classes)\n",
    "\n",
    "        self.n_classes = n_classes\n",
    "        self.d_embed = d_embed\n",
    "\n",
    "    def forward(self, img, text):\n",
    "        img_outputs = self.image_encoder(img)\n",
    "        img_features = img_outputs.last_hidden_state[:, 0, :].view(-1, 100, self.d_embed)\n",
    "        img_features = torch.mean(img_features, 1)\n",
    "        img_embed = self.image_proj(img_features)\n",
    "        img_embed = img_embed / torch.norm(img_embed, dim=-1, keepdim=True)\n",
    "\n",
    "        text_outputs = self.text_encoder(**text)\n",
    "        text_embed = text_outputs.pooler_output\n",
    "        text_embed = self.text_proj(text_embed)\n",
    "        text_embed = text_embed / torch.norm(text_embed, dim=-1, keepdim=True)\n",
    "\n",
    "        logits = img_embed @ text_embed.T\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at owkin/phikon were not used when initializing ViTModel: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing ViTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "seq_max_length = 50\n",
    "tokenizer = BertTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "\n",
    "def contrastive_loss(logits, labels):\n",
    "    image_loss = F.cross_entropy(logits, labels, reduction=\"mean\")\n",
    "    text_loss = F.cross_entropy(logits.transpose(0, 1), labels, reduction=\"mean\")\n",
    "    loss = (image_loss + text_loss) / 2\n",
    "\n",
    "    return loss\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, image_processor=None):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    best_loss = np.inf\n",
    "    for batch, (imgs, texts, _) in enumerate(dataloader):\n",
    "        labels = torch.tensor(range(imgs.shape[0])).to(device)\n",
    "        imgs = imgs.view(-1, 3, 224, 224)\n",
    "        texts = tokenizer(texts, padding='max_length', max_length=seq_max_length, return_tensors='pt').to(device)\n",
    "\n",
    "\n",
    "        if image_processor:\n",
    "            imgs = image_processor(imgs, return_tensors=\"pt\").to(device)\n",
    "            # Compute prediction and loss\n",
    "            logits = model(imgs['pixel_values'], texts)\n",
    "        else:\n",
    "            # Compute prediction and loss\n",
    "            logits = model(imgs, texts)\n",
    "        loss = loss_fn(logits, labels)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_acc = torch.sum(torch.argmax(logits, axis=1) == labels) / logits.shape[0]\n",
    "\n",
    "        loss, current = loss.item(), (batch + 1) * batch_size\n",
    "        if train_acc == 1:\n",
    "            if loss < best_loss:\n",
    "                torch.save(model.state_dict(), '/scratch1/yuqiuwan/CSCI567/bert_phikon_model_state_dict_current_best.pt')\n",
    "            \n",
    "      \n",
    "        print(f\"loss: {loss:>7f}; train_acc: {train_acc:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "######################## Train CLIP ########################\n",
    "batch_size = 3\n",
    "dropout = 0.0\n",
    "learning_rate = 10**(-3)\n",
    "\n",
    "train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# load phikon\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"owkin/phikon\")\n",
    "img_encoder = ViTModel.from_pretrained(\"owkin/phikon\", add_pooling_layer=False)\n",
    "img_encoder.eval()\n",
    "\n",
    "# load bert\n",
    "text_encoder = BertModel.from_pretrained('bert-base-uncased')\n",
    "text_encoder.eval()\n",
    "\n",
    "clip_model = CLIP(img_encoder, text_encoder, d_embed=768, n_classes=5).to(device)\n",
    "# clip_model.load_state_dict(torch.load('/scratch1/yuqiuwan/CSCI567/trainedModels/bert_phikon_model_state_dict_current_best.pt'))\n",
    "\n",
    "# Freeze the pre-trained model\n",
    "for p in clip_model.image_encoder.parameters():\n",
    "    p.requires_grad = False\n",
    "for p in clip_model.text_encoder.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "optimizer = torch.optim.Adam(clip_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 19\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, clip_model, contrastive_loss, optimizer, image_processor)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(clip_model.state_dict(), '/scratch1/yuqiuwan/CSCI567/bert_phikon_model_state_dict_last_epoch_output.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip_model = CLIP(img_encoder, text_encoder, d_embed=768, n_classes=5).to(device)\n",
    "clip_model.load_state_dict(torch.load('/scratch1/yuqiuwan/CSCI567/trainedModels/bert_phikon_model_state_dict_last_epoch_output.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9743, -0.3738,  0.3041, -0.3364,  0.5164]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([0], device='cuda:0')\n",
      "0 correct_num: tensor(1, device='cuda:0')\n",
      "tensor([[-0.6804, -0.2192,  0.5631,  0.3523, -0.0291]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([2], device='cuda:0')\n",
      "1 correct_num: tensor(2, device='cuda:0')\n",
      "tensor([[-0.3674, -0.5154,  0.1742,  0.9608, -0.7074]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "2 correct_num: tensor(3, device='cuda:0')\n",
      "tensor([[-0.5799, -0.4739,  0.4927,  0.8359, -0.2638]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "3 correct_num: tensor(4, device='cuda:0')\n",
      "tensor([[-0.4328,  0.9029, -0.4565, -0.7340,  0.2061]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([1], device='cuda:0')\n",
      "4 correct_num: tensor(5, device='cuda:0')\n",
      "tensor([[-0.4934, -0.4036,  0.0249,  0.9065, -0.6038]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "5 correct_num: tensor(6, device='cuda:0')\n",
      "tensor([[ 0.7598,  0.1953, -0.3864, -0.6710,  0.2726]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([0], device='cuda:0')\n",
      "6 correct_num: tensor(7, device='cuda:0')\n",
      "tensor([[-0.5039, -0.1018, -0.3196,  0.7591, -0.9013]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "7 correct_num: tensor(8, device='cuda:0')\n",
      "tensor([[-0.1816,  0.8379, -0.6213, -0.8414,  0.3192]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([1], device='cuda:0')\n",
      "8 correct_num: tensor(9, device='cuda:0')\n",
      "tensor([[-0.4486,  0.9278, -0.5819, -0.7223,  0.1265]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([1], device='cuda:0')\n",
      "9 correct_num: tensor(10, device='cuda:0')\n",
      "tensor([[ 0.8474,  0.1172, -0.2985, -0.5678,  0.2180]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([0], device='cuda:0')\n",
      "10 correct_num: tensor(11, device='cuda:0')\n",
      "tensor([[-0.2478,  0.9029, -0.6043, -0.8298,  0.2673]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([4], device='cuda:0')\n",
      "11 correct_num: tensor(11, device='cuda:0')\n",
      "tensor([[-0.7387, -0.0846, -0.1024,  0.7869, -0.7429]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "12 correct_num: tensor(12, device='cuda:0')\n",
      "tensor([[-0.6535,  0.4349, -0.6498,  0.3492, -0.8790]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "13 correct_num: tensor(12, device='cuda:0')\n",
      "tensor([[ 0.0913, -0.8957,  0.6278,  0.8953, -0.2084]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "14 correct_num: tensor(13, device='cuda:0')\n",
      "tensor([[-0.0698, -0.6926,  0.3253,  0.9570, -0.6001]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "15 correct_num: tensor(14, device='cuda:0')\n",
      "tensor([[-0.5238, -0.1999, -0.1043,  0.8726, -0.8153]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "16 correct_num: tensor(15, device='cuda:0')\n",
      "tensor([[ 0.2656, -0.9804,  0.6363,  0.7061,  0.0073]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "17 correct_num: tensor(16, device='cuda:0')\n",
      "tensor([[-0.4860, -0.5528,  0.3567,  0.9461, -0.4991]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "18 correct_num: tensor(17, device='cuda:0')\n",
      "tensor([[ 0.2282,  0.7148, -0.4533, -0.9794,  0.4696]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([0], device='cuda:0')\n",
      "19 correct_num: tensor(17, device='cuda:0')\n",
      "tensor([[ 0.0953,  0.5125, -0.2255, -0.8918,  0.7201]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([4], device='cuda:0')\n",
      "20 correct_num: tensor(18, device='cuda:0')\n",
      "tensor([[-0.3577, -0.4938,  0.0966,  0.9637, -0.6481]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "21 correct_num: tensor(19, device='cuda:0')\n",
      "tensor([[ 0.7706,  0.0496, -0.0598, -0.7562,  0.5836]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([0], device='cuda:0')\n",
      "22 correct_num: tensor(20, device='cuda:0')\n",
      "tensor([[-0.4115, -0.2743, -0.0964,  0.8998, -0.8052]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "23 correct_num: tensor(21, device='cuda:0')\n",
      "tensor([[-0.9297,  0.4595, -0.0990,  0.0918, -0.1071]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "24 correct_num: tensor(21, device='cuda:0')\n",
      "tensor([[-0.6769,  0.8074, -0.8143, -0.1813, -0.5617]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "25 correct_num: tensor(21, device='cuda:0')\n",
      "tensor([[-0.6541,  0.9020, -0.5385, -0.5223, -0.0172]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([1], device='cuda:0')\n",
      "26 correct_num: tensor(22, device='cuda:0')\n",
      "tensor([[-0.6246, -0.3252,  0.2210,  0.8540, -0.6716]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([2], device='cuda:0')\n",
      "27 correct_num: tensor(22, device='cuda:0')\n",
      "tensor([[-0.8528,  0.7068, -0.6139,  0.0346, -0.5319]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([1], device='cuda:0')\n",
      "28 correct_num: tensor(23, device='cuda:0')\n",
      "tensor([[ 0.5769,  0.2178, -0.1172, -0.8775,  0.6855]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "29 correct_num: tensor(23, device='cuda:0')\n",
      "tensor([[-0.4863,  0.9429, -0.5688, -0.6601, -0.0125]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([1], device='cuda:0')\n",
      "30 correct_num: tensor(24, device='cuda:0')\n",
      "tensor([[-0.8762,  0.2581, -0.3132,  0.5308, -0.7154]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "31 correct_num: tensor(25, device='cuda:0')\n",
      "tensor([[-0.8291,  0.2417, -0.3792,  0.5320, -0.8081]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "32 correct_num: tensor(26, device='cuda:0')\n",
      "tensor([[-0.2988,  0.9007, -0.5329, -0.8340,  0.2231]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([1], device='cuda:0')\n",
      "33 correct_num: tensor(27, device='cuda:0')\n",
      "tensor([[-0.1276,  0.5979, -0.3213, -0.7989,  0.6184]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([4], device='cuda:0')\n",
      "34 correct_num: tensor(28, device='cuda:0')\n",
      "tensor([[ 0.8771,  0.0727, -0.1938, -0.6004,  0.3174]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([0], device='cuda:0')\n",
      "35 correct_num: tensor(29, device='cuda:0')\n",
      "tensor([[-0.5907,  0.1042, -0.4834,  0.6307, -0.8784]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "36 correct_num: tensor(30, device='cuda:0')\n",
      "tensor([[ 0.5823,  0.4332, -0.3738, -0.8952,  0.3982]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([0], device='cuda:0')\n",
      "37 correct_num: tensor(31, device='cuda:0')\n",
      "tensor([[-0.3547, -0.4467,  0.0626,  0.9558, -0.7348]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "38 correct_num: tensor(32, device='cuda:0')\n",
      "tensor([[-0.1435, -0.6847,  0.2813,  0.9758, -0.5857]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "39 correct_num: tensor(33, device='cuda:0')\n",
      "tensor([[-0.8235,  0.6433, -0.6785,  0.1127, -0.6153]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([1], device='cuda:0')\n",
      "40 correct_num: tensor(34, device='cuda:0')\n",
      "tensor([[-0.0261, -0.8959,  0.8327,  0.7401,  0.0035]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([2], device='cuda:0')\n",
      "41 correct_num: tensor(35, device='cuda:0')\n",
      "tensor([[-0.5519, -0.1795, -0.1440,  0.8151, -0.8862]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "42 correct_num: tensor(36, device='cuda:0')\n",
      "tensor([[ 0.6292, -0.8635,  0.8488,  0.2509,  0.4125]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([2], device='cuda:0')\n",
      "43 correct_num: tensor(37, device='cuda:0')\n",
      "tensor([[ 0.3385, -0.7992,  0.9550,  0.2412,  0.5746]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([2], device='cuda:0')\n",
      "44 correct_num: tensor(38, device='cuda:0')\n",
      "tensor([[-0.5826, -0.4692,  0.4033,  0.8616, -0.5054]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "45 correct_num: tensor(39, device='cuda:0')\n",
      "tensor([[-0.3476,  0.9392, -0.6035, -0.7680,  0.0498]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([1], device='cuda:0')\n",
      "46 correct_num: tensor(40, device='cuda:0')\n",
      "tensor([[-0.0027, -0.9163,  0.6569,  0.8456, -0.1195]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "47 correct_num: tensor(41, device='cuda:0')\n",
      "tensor([[-0.7529,  0.1571, -0.2205,  0.6478, -0.5782]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "48 correct_num: tensor(42, device='cuda:0')\n",
      "tensor([[ 0.8289, -0.0336, -0.1969, -0.3295, -0.0526]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([0], device='cuda:0')\n",
      "49 correct_num: tensor(43, device='cuda:0')\n",
      "tensor([[-0.7533, -0.0019, -0.1760,  0.7385, -0.7848]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "50 correct_num: tensor(44, device='cuda:0')\n",
      "tensor([[ 0.4632,  0.4061, -0.6484, -0.2967, -0.3761]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "51 correct_num: tensor(44, device='cuda:0')\n",
      "tensor([[ 0.1487, -0.8824,  0.5042,  0.8971, -0.3025]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "52 correct_num: tensor(45, device='cuda:0')\n",
      "tensor([[ 0.6899, -0.7620,  0.7595,  0.0169,  0.6357]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "53 correct_num: tensor(45, device='cuda:0')\n",
      "tensor([[ 0.8424,  0.0052, -0.0941, -0.6650,  0.4214]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([0], device='cuda:0')\n",
      "54 correct_num: tensor(46, device='cuda:0')\n",
      "tensor([[ 0.7370,  0.2900, -0.2976, -0.7944,  0.4137]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([0], device='cuda:0')\n",
      "55 correct_num: tensor(47, device='cuda:0')\n",
      "tensor([[ 0.1021,  0.6093, -0.1212, -0.9314,  0.6923]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "56 correct_num: tensor(47, device='cuda:0')\n",
      "tensor([[-0.2699, -0.5669,  0.1721,  0.9498, -0.7185]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "57 correct_num: tensor(48, device='cuda:0')\n",
      "tensor([[-0.7141,  0.8843, -0.5143, -0.4001, -0.0725]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([1], device='cuda:0')\n",
      "58 correct_num: tensor(49, device='cuda:0')\n",
      "tensor([[ 0.7006,  0.3306, -0.3321, -0.8206,  0.4258]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([0], device='cuda:0')\n",
      "59 correct_num: tensor(50, device='cuda:0')\n",
      "tensor([[ 0.8393, -0.7400,  0.5690,  0.0273,  0.3501]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([1], device='cuda:0')\n",
      "60 correct_num: tensor(50, device='cuda:0')\n",
      "tensor([[-0.6828,  0.4509, -0.6851,  0.3464, -0.7872]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "61 correct_num: tensor(50, device='cuda:0')\n",
      "tensor([[-0.4606, -0.3707,  0.0694,  0.9410, -0.7466]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "62 correct_num: tensor(51, device='cuda:0')\n",
      "tensor([[-0.3887,  0.9657, -0.6590, -0.7264,  0.0449]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([1], device='cuda:0')\n",
      "63 correct_num: tensor(52, device='cuda:0')\n",
      "tensor([[-0.6974,  0.9038, -0.6830, -0.3606, -0.1995]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([1], device='cuda:0')\n",
      "64 correct_num: tensor(53, device='cuda:0')\n",
      "tensor([[-0.9311,  0.6364, -0.4855, -0.0558, -0.3303]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([2], device='cuda:0')\n",
      "65 correct_num: tensor(53, device='cuda:0')\n",
      "tensor([[-0.3996, -0.4873,  0.2110,  0.9718, -0.6723]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "66 correct_num: tensor(54, device='cuda:0')\n",
      "tensor([[ 0.8581, -0.0699,  0.1210, -0.6617,  0.6733]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([0], device='cuda:0')\n",
      "67 correct_num: tensor(55, device='cuda:0')\n",
      "tensor([[-0.0326,  0.7330, -0.3465, -0.9367,  0.5567]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([4], device='cuda:0')\n",
      "68 correct_num: tensor(55, device='cuda:0')\n",
      "tensor([[-0.6112, -0.2293, -0.0597,  0.8736, -0.7172]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "69 correct_num: tensor(56, device='cuda:0')\n",
      "tensor([[-0.4457, -0.4139,  0.1389,  0.9605, -0.6939]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "70 correct_num: tensor(57, device='cuda:0')\n",
      "tensor([[ 0.7403,  0.1179, -0.4937, -0.4436,  0.0516]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([0], device='cuda:0')\n",
      "71 correct_num: tensor(58, device='cuda:0')\n",
      "tensor([[-0.0185, -0.4282, -0.1882,  0.7850, -0.7603]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "72 correct_num: tensor(59, device='cuda:0')\n",
      "tensor([[-0.4324, -0.4580,  0.0557,  0.9351, -0.6608]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "73 correct_num: tensor(60, device='cuda:0')\n",
      "tensor([[ 0.1185,  0.6456, -0.3342, -0.9565,  0.6227]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([4], device='cuda:0')\n",
      "74 correct_num: tensor(60, device='cuda:0')\n",
      "tensor([[-0.3750, -0.3576, -0.0039,  0.9368, -0.7649]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "75 correct_num: tensor(61, device='cuda:0')\n",
      "tensor([[ 0.8549, -0.2733, -0.1944, -0.0495, -0.0721]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([0], device='cuda:0')\n",
      "76 correct_num: tensor(62, device='cuda:0')\n",
      "tensor([[-0.7043,  0.8557, -0.7520, -0.1963, -0.4816]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([1], device='cuda:0')\n",
      "77 correct_num: tensor(63, device='cuda:0')\n",
      "tensor([[ 0.5346,  0.4206, -0.6579, -0.6784,  0.0512]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([1], device='cuda:0')\n",
      "78 correct_num: tensor(63, device='cuda:0')\n",
      "tensor([[-0.2958, -0.7540,  0.4817,  0.8915, -0.4203]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "79 correct_num: tensor(64, device='cuda:0')\n",
      "tensor([[ 0.6980,  0.3855, -0.3794, -0.7918,  0.3646]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([0], device='cuda:0')\n",
      "80 correct_num: tensor(65, device='cuda:0')\n",
      "tensor([[-0.3201,  0.9018, -0.5801, -0.7847,  0.2703]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([1], device='cuda:0')\n",
      "81 correct_num: tensor(66, device='cuda:0')\n",
      "tensor([[-0.3823, -0.5049,  0.2115,  0.9654, -0.6913]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "82 correct_num: tensor(67, device='cuda:0')\n",
      "tensor([[-0.4521, -0.4070,  0.0640,  0.9259, -0.7727]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "83 correct_num: tensor(68, device='cuda:0')\n",
      "tensor([[ 0.0425,  0.8696, -0.6142, -0.9156,  0.2577]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([1], device='cuda:0')\n",
      "84 correct_num: tensor(69, device='cuda:0')\n",
      "tensor([[ 0.7079,  0.3104, -0.4973, -0.6557,  0.1623]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([0], device='cuda:0')\n",
      "85 correct_num: tensor(70, device='cuda:0')\n",
      "tensor([[ 0.7689,  0.2116, -0.3715, -0.6189,  0.1355]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([0], device='cuda:0')\n",
      "86 correct_num: tensor(71, device='cuda:0')\n",
      "tensor([[-0.7780, -0.0383,  0.4421,  0.3362, -0.0661]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([1], device='cuda:0')\n",
      "87 correct_num: tensor(71, device='cuda:0')\n",
      "tensor([[ 0.1558, -0.9440,  0.5814,  0.8304, -0.2253]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "88 correct_num: tensor(72, device='cuda:0')\n",
      "tensor([[ 0.0202,  0.7789, -0.3725, -0.9505,  0.3682]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([2], device='cuda:0')\n",
      "89 correct_num: tensor(72, device='cuda:0')\n",
      "tensor([[-0.3504,  0.9241, -0.6072, -0.7861,  0.1749]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([1], device='cuda:0')\n",
      "90 correct_num: tensor(73, device='cuda:0')\n",
      "tensor([[-0.5984,  0.9498, -0.6613, -0.5251, -0.0943]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([1], device='cuda:0')\n",
      "91 correct_num: tensor(74, device='cuda:0')\n",
      "tensor([[-0.8597,  0.0142, -0.1993,  0.6211, -0.6306]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "92 correct_num: tensor(75, device='cuda:0')\n",
      "tensor([[-0.1547, -0.7468,  0.4389,  0.9819, -0.4512]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "93 correct_num: tensor(76, device='cuda:0')\n",
      "tensor([[ 0.3526,  0.6486, -0.4820, -0.9609,  0.4395]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([0], device='cuda:0')\n",
      "94 correct_num: tensor(76, device='cuda:0')\n",
      "tensor([[-0.5051, -0.5197,  0.3024,  0.9421, -0.4726]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "95 correct_num: tensor(77, device='cuda:0')\n",
      "tensor([[ 0.1415, -0.9132,  0.5800,  0.7753,  0.0049]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "96 correct_num: tensor(78, device='cuda:0')\n",
      "tensor([[-0.7180, -0.1287, -0.0274,  0.8126, -0.7360]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "97 correct_num: tensor(79, device='cuda:0')\n",
      "tensor([[ 0.0268, -0.8256,  0.5925,  0.9089, -0.3708]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "98 correct_num: tensor(80, device='cuda:0')\n",
      "tensor([[ 0.4898, -0.6319,  0.9105, -0.0158,  0.6021]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "99 correct_num: tensor(80, device='cuda:0')\n",
      "tensor([[-0.3607, -0.5977,  0.3066,  0.9794, -0.5836]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "100 correct_num: tensor(81, device='cuda:0')\n",
      "tensor([[-0.4679,  0.9654, -0.6446, -0.6644,  0.0276]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([1], device='cuda:0')\n",
      "101 correct_num: tensor(82, device='cuda:0')\n",
      "tensor([[-0.4376,  0.3316,  0.0014, -0.4543,  0.5979]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([4], device='cuda:0')\n",
      "102 correct_num: tensor(83, device='cuda:0')\n",
      "tensor([[-0.4129,  0.9754, -0.7225, -0.6775, -0.0192]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([1], device='cuda:0')\n",
      "103 correct_num: tensor(84, device='cuda:0')\n",
      "tensor([[ 0.7474,  0.1927, -0.1040, -0.8202,  0.5796]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([0], device='cuda:0')\n",
      "104 correct_num: tensor(85, device='cuda:0')\n",
      "tensor([[-0.4777, -0.3919,  0.1999,  0.9437, -0.6810]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([3], device='cuda:0')\n",
      "105 correct_num: tensor(86, device='cuda:0')\n",
      "tensor([[ 0.9038, -0.0345, -0.1412, -0.5551,  0.3955]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>) True label: tensor([0], device='cuda:0')\n",
      "106 correct_num: tensor(87, device='cuda:0')\n",
      "Test_accuracy: tensor(0.8131, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "class_ind = {'CC':0, 'EC':1, 'LGSC':2, 'HGSC':3, 'MC':4}\n",
    "\n",
    "def test_loop(dataloader, model, image_processor=None):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    # texts = ['Cells are clear and transparent', \n",
    "    #          'Cells exhibit a back-to-back glandular arrangement', \n",
    "    #          'This cell type includes cells resembling normal healthy cells, cells with single nuclei, and living cells', \n",
    "    #          'Numerous cells frequently exhibit deformed shapes, several cells contain multiple nuclei, and many tissues typically contain dead cells.',\n",
    "    #          'Cells have goblet-like appearance']\n",
    "    \n",
    "    texts = ['This type of cells have cell cytoplasm that are see through, and often have clear cell boundaries', \n",
    "            'Cells exhibit a back-to-back glandular pattern', \n",
    "            'This type of cells have cells close to normal healthy cells, cells containing single nuclei, and alive cell', \n",
    "            'There are many cells that are often deformed in shape, and many cells with multiple nucleus, and tissues often present many dead cells',\n",
    "            'This type of cells often have goblet cells, they are often goblet-like or cell-like']\n",
    "    \n",
    "    texts = tokenizer(texts, padding='max_length', max_length=30, return_tensors='pt').to(device)\n",
    "    \n",
    "    correct_num = 0\n",
    "    for batch, (imgs, _, labels) in enumerate(dataloader):\n",
    "        imgs = imgs.view(-1, 3, 224, 224)\n",
    "        \n",
    "        if image_processor:\n",
    "            imgs = image_processor(imgs, return_tensors=\"pt\").to(device)\n",
    "            # Compute prediction and loss\n",
    "            logits = model(imgs['pixel_values'], texts)\n",
    "        else:\n",
    "            # Compute prediction and loss\n",
    "            logits = model(imgs, texts)\n",
    "        print(logits, 'True label:', labels)\n",
    "\n",
    "        correct_num += torch.sum(torch.argmax(logits, axis=1) == labels)\n",
    "        print(batch, 'correct_num:', correct_num)\n",
    "\n",
    "    test_acc = correct_num  / size\n",
    "    print('Test_accuracy:', test_acc)\n",
    "\n",
    "test_dataloader = DataLoader(test_set, batch_size=1, shuffle=True)\n",
    "test_loop(test_dataloader, clip_model, image_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
